{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Words Remover\n",
    "\n",
    "Stop words remuves words such as the, a, and an, auxiliary verbs such as do, be, and will,\n",
    "and prepositions such as on, around, and beneath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.ml.feature.Tokenizer\n",
    "import org.apache.spark.ml.feature.{Tokenizer,StopWordsRemover,CountVectorizer}\n",
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.linalg.Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a set of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [id: int, doc: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[id: int, doc: string]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = List( (0,\"The sun is shining\"),\n",
    "                (1,\"The weather is sweet, sweet\"),\n",
    "                (2,\"The sun is shining and the weather is sweet\")).toDF(\"id\",\"doc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|                 doc|\n",
      "+---+--------------------+\n",
      "|  0|  The sun is shining|\n",
      "|  1|The weather is sw...|\n",
      "|  2|The sun is shinin...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer = tok_9de3b95c0a54\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tok_9de3b95c0a54"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tokenizer = new Tokenizer().\n",
    "  setInputCol(\"doc\").\n",
    "  setOutputCol(\"raw_words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "remover = stopWords_d5dde8f20b91\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "stopWords_d5dde8f20b91"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val remover = new StopWordsRemover().\n",
    "  setInputCol(\"raw_words\").\n",
    "  setOutputCol(\"filtered_words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cv = cntVec_afcac1c186f8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "cntVec_afcac1c186f8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cv = new CountVectorizer().\n",
    "  setInputCol(\"filtered_words\").\n",
    "  setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline = pipeline_73a6fa065fc2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_73a6fa065fc2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pipeline = new Pipeline().\n",
    "  setStages(Array(tokenizer, remover, cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 0) / 4]+---+--------------------+--------------------+--------------------+--------------------+\n",
      "| id|                 doc|           raw_words|      filtered_words|            features|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+\n",
      "|  0|  The sun is shining|[the, sun, is, sh...|      [sun, shining]| (5,[1,2],[1.0,1.0])|\n",
      "|  1|The weather is sw...|[the, weather, is...|[weather, sweet,,...|(5,[0,3,4],[1.0,1...|\n",
      "|  2|The sun is shinin...|[the, sun, is, sh...|[sun, shining, we...|(5,[0,1,2,3],[1.0...|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df_v = [id: int, doc: string ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[id: int, doc: string ... 3 more fields]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df_v = pipeline.fit(df).transform(df)\n",
    "df_v.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0,1.0,1.0,0.0,0.0], [1.0,0.0,0.0,1.0,1.0], [1.0,1.0,1.0,1.0,0.0]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_v.select(\"features\").collect.map(row => row(0).asInstanceOf[Vector].toDense)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
