{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing trick\n",
    "Hashing trick works by applying a hash function to the features and using their hash values \n",
    "as indices directly, rather than building a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.ml.feature.{Tokenizer,HashingTF}\n",
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.linalg.Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a set of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [id: int, doc: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[id: int, doc: string]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = List( (0,\"The sun is shining\"),\n",
    "                (1,\"The weather is sweet, sweet\"),\n",
    "                (2,\"The sun is shining and the weather is sweet\")).toDF(\"id\",\"doc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|                 doc|\n",
      "+---+--------------------+\n",
      "|  0|  The sun is shining|\n",
      "|  1|The weather is sw...|\n",
      "|  2|The sun is shinin...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer = tok_5683f06fbb75\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tok_5683f06fbb75"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tokenizer = new Tokenizer().\n",
    "  setInputCol(\"doc\").\n",
    "  setOutputCol(\"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hashingTF = hashingTF_e98c19007874\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "hashingTF_e98c19007874"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val hashingTF = new HashingTF().\n",
    "  setInputCol(\"words\").\n",
    "  setOutputCol(\"features\").\n",
    "  setNumFeatures(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline = pipeline_448e4f6269e6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_448e4f6269e6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pipeline = new Pipeline().\n",
    "  setStages(Array(tokenizer, hashingTF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| id|                 doc|            features|\n",
      "+---+--------------------+--------------------+\n",
      "|  0|  The sun is shining|(10,[0,1,6],[2.0,...|\n",
      "|  1|The weather is sw...|(10,[0,1,2,4,7],[...|\n",
      "|  2|The sun is shinin...|(10,[0,1,2,3,4,6]...|\n",
      "+---+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df_v = [id: int, doc: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[id: int, doc: string ... 1 more field]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df_v = pipeline.fit(df).transform(df).select(\"id\",\"doc\",\"features\")\n",
    "df_v.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0], [1.0,1.0,1.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0], [3.0,2.0,1.0,1.0,1.0,0.0,1.0,0.0,0.0,0.0]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_v.select(\"features\").collect.map(row => row(0).asInstanceOf[Vector].toDense)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
